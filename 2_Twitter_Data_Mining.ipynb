{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the Json Files & Data Mining\n",
    "\n",
    "The tweets were saved on 73 json files with sizes ranging from 100 MB to ~19 GBs. All the files were broken to pieces of 100,000 lines (~ 700 MB) so that they can be easily processed on my PC.\n",
    "I process the json files individually and save the resulting dataframes in CSV format. These CSV files are significantly smaller (~ 3-8 MB) and will be concatenated later.\n",
    "\n",
    "I have cetegorized the tweets to tweets and retweets and saved them in separate CSV files. Retweet dataframes contain information about the retweet and the original tweet. The final tweet csv file is ~570 MB and contains ~1.7 million tweets. The final retweet csv file is ~1.4 GB and contains ~2.9 million retweets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# function to extract user_mentions from user_mentions list of dictionaries\n",
    "userextract = lambda x: [y['screen_name'] for y in x] if len(x)> 0 else []\n",
    "# function to extract hashtags from hashtags list of dictionaries\n",
    "hashextract = lambda x: [y['text'] for y in x] if len(x)> 0 else []\n",
    "\n",
    "# function to extract extended state, user-mentions, hashtags, and full-texts\n",
    "def multi_functions(tweet):\n",
    "    if 'extended_tweet' in tweet.keys():\n",
    "        return [ True, userextract(tweet['extended_tweet']['entities']['user_mentions']), \\\n",
    "                hashextract(tweet['extended_tweet']['entities']['hashtags']), tweet['extended_tweet']['full_text']]\n",
    "    else:\n",
    "        return [False, userextract(tweet['entities']['user_mentions']),\\\n",
    "                hashextract(tweet['entities']['hashtags']), tweet['text']]\n",
    "\n",
    "# csv file to keep track of the number of the duplicate tweets, change 1000 if you have more than 1000 files  \n",
    "tweet_counter = pd.DataFrame(index=np.arange(1000), \\\n",
    "                             columns=['filename', 'recorded_tweets', 'recorded_retweets', 'tweet_counts', 'retweet_count'])\n",
    "\n",
    "# using glob to read the file names\n",
    "filenames = glob('data/blackfriday*.json')\n",
    "# or your own list\n",
    "#filenames = ['blackfriday46_0.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "tweets_data = []\n",
    "retweets_data = []\n",
    "data = []\n",
    "\n",
    "# reading the json files\n",
    "for filename in filenames:\n",
    "    tweets_file = open(filename, \"r\")\n",
    "    for line in tweets_file:\n",
    "        try:\n",
    "            tweet = json.loads(line)\n",
    "            data.append(tweet)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    tweets_file.close()\n",
    "\n",
    "    #############################################################################################\n",
    "\n",
    "    # dividing the tweets to tweets & retweets categories\n",
    "    for tweet in data:\n",
    "        if 'text' in tweet.keys(): # filter error lines \n",
    "            if 'retweeted_status' in tweet.keys():\n",
    "                retweets_data.append(tweet)\n",
    "            else:\n",
    "                tweets_data.append(tweet)\n",
    "          \n",
    "    data = []\n",
    "    \n",
    "    tweet_counter.iloc[i, 0] = filename\n",
    "    tweet_counter.iloc[i, 1] = len(tweets_data)\n",
    "    tweet_counter.iloc[i, 2] = len(retweets_data)\n",
    "\n",
    "    #############################################################################################\n",
    "\n",
    "    # building a tweets dataframe & saving it in csv format\n",
    "    tweets = pd.DataFrame()\n",
    "    tweets['id'] = [tweet['id'] for tweet in tweets_data]\n",
    "    tweets['created_at'] = [tweet['created_at'] for tweet in tweets_data]\n",
    "    tweets['language'] = [tweet['lang'] for tweet in tweets_data]\n",
    "    tweets['coordinates'] = [tweet['coordinates'] for tweet in tweets_data]\n",
    "\n",
    "    tweets['mixed'] = [multi_functions(tweet) for tweet in tweets_data]\n",
    "    tweets['extended'] = tweets['mixed'].apply(lambda x: x[0])\n",
    "    tweets['user_mentions'] = tweets['mixed'].apply(lambda x: x[1])\n",
    "    tweets['hashtags'] = tweets['mixed'].apply(lambda x: x[2])\n",
    "    tweets['full_text'] = tweets['mixed'].apply(lambda x: x[3])\n",
    "    tweets['full_text'] = tweets['full_text'].apply(lambda x: [x])\n",
    "    tweets.drop('mixed', axis=1, inplace=True)\n",
    "\n",
    "    tweets['user_name'] = [tweet['user']['screen_name'] for tweet in tweets_data]\n",
    "    tweets['verified'] = [ True if tweet['user']['verified'] is True else False for tweet in tweets_data]\n",
    "    tweets['user_followers'] = [tweet['user']['followers_count'] for tweet in tweets_data]\n",
    "    tweets['user_friends'] = [tweet['user']['friends_count'] for tweet in tweets_data]\n",
    "    tweets['user_favourites_count'] = [tweet['user']['favourites_count'] for tweet in tweets_data]\n",
    "    tweets['user_listed_count'] = [tweet['user']['listed_count'] for tweet in tweets_data]\n",
    "    tweets['user_statuses_count'] = [tweet['user']['statuses_count'] for tweet in tweets_data]\n",
    "    tweets['user_created_at'] = [tweet['user']['created_at'] for tweet in tweets_data]\n",
    "    tweets['retweet'] = False\n",
    "    \n",
    "    tweets = tweets.drop_duplicates('id')\n",
    "    \n",
    "    filename_tweets = 'output/tweets'+str(i)\n",
    "    tweets.to_csv(filename_tweets, index=False)\n",
    "    tweet_counter.iloc[i, 3] = len(tweets)\n",
    "    tweets_data = []\n",
    "    tweets = pd.DataFrame()\n",
    "    \n",
    "    #############################################################################################\n",
    "    \n",
    "    # building a retweets dataframe & saving it in csv format\n",
    "    retweets = pd.DataFrame()\n",
    "    retweets['id'] = [tweet['id'] for tweet in retweets_data]\n",
    "    retweets['created_at'] = [tweet['created_at'] for tweet in retweets_data]\n",
    "    retweets['language'] = [tweet['lang'] for tweet in retweets_data]\n",
    "    retweets['coordinates'] = [tweet['coordinates'] for tweet in retweets_data]\n",
    "\n",
    "    retweets['mixed'] = [multi_functions(tweet['retweeted_status']) for tweet in retweets_data]\n",
    "    retweets['extended'] = retweets['mixed'].apply(lambda x: x[0])\n",
    "    retweets['user_mentions'] = retweets['mixed'].apply(lambda x: x[1])\n",
    "    retweets['hashtags'] = retweets['mixed'].apply(lambda x: x[2])\n",
    "    retweets['full_text'] = retweets['mixed'].apply(lambda x: x[3])\n",
    "    retweets['full_text'] = retweets['full_text'].apply(lambda x: [x])\n",
    "    retweets.drop('mixed', axis=1, inplace=True)\n",
    "\n",
    "    retweets['user_name'] = [tweet['user']['screen_name'] for tweet in retweets_data]\n",
    "    retweets['user_followers'] = [tweet['user']['followers_count'] for tweet in retweets_data]\n",
    "    retweets['user_friends'] = [tweet['user']['friends_count'] for tweet in retweets_data]\n",
    "    retweets['user_favourites_count'] = [tweet['user']['favourites_count'] for tweet in retweets_data]\n",
    "    retweets['user_listed_count'] = [tweet['user']['listed_count'] for tweet in retweets_data]\n",
    "    retweets['user_statuses_count'] = [tweet['user']['statuses_count'] for tweet in retweets_data]\n",
    "    retweets['user_created_at'] = [tweet['user']['created_at'] for tweet in retweets_data]\n",
    "\n",
    "    retweets['retweet'] = True\n",
    "    retweets['orig_id'] = [tweet['retweeted_status']['id'] for tweet in retweets_data]\n",
    "    retweets['orig_created_at'] = [tweet['retweeted_status']['created_at'] for tweet in retweets_data]\n",
    "    retweets['orig_user'] = [tweet['retweeted_status']['user']['screen_name'] for tweet in retweets_data]\n",
    "    retweets['verified'] = [ True if tweet['retweeted_status']['user']['verified'] is True else False for tweet in retweets_data]\n",
    "    retweets['orig_user_followers'] = [tweet['retweeted_status']['user']['followers_count'] for tweet in retweets_data]\n",
    "    retweets['orig_user_friends'] = [tweet['retweeted_status']['user']['friends_count'] for tweet in retweets_data]\n",
    "    retweets['orig_user_favourites'] = [tweet['retweeted_status']['user']['favourites_count'] for tweet in retweets_data]\n",
    "    retweets['orig_user_listed'] = [tweet['retweeted_status']['user']['listed_count'] for tweet in retweets_data]\n",
    "    retweets['orig_user_statuses'] = [tweet['retweeted_status']['user']['statuses_count'] for tweet in retweets_data]\n",
    "    retweets['orig_user_created_at'] = [tweet['retweeted_status']['user']['created_at'] for tweet in retweets_data]\n",
    "\n",
    "    retweets = retweets.drop_duplicates('id') \n",
    "\n",
    "    filename_retweets = 'output/retweets'+str(i)\n",
    "    retweets.to_csv(filename_retweets, index=False)\n",
    "    tweet_counter.iloc[i, 4] = len(retweets)\n",
    "    retweets_data = []\n",
    "    retweets = pd.DataFrame()\n",
    "    \n",
    "    # print(i)\n",
    "    i +=1\n",
    "\n",
    "# saving the tweet counter data\n",
    "tweet_counter.to_csv('tweet_counter.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concatanation\n",
    "*This section can be run independent of the above section*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_tweets = glob('output/tweets*')\n",
    "\n",
    "list_tweets = []\n",
    "\n",
    "for filename in filenames_tweets:\n",
    "    df_chunk = pd.read_csv(filename)\n",
    "    list_tweets.append(df_chunk)\n",
    "\n",
    "# Free up the memory\n",
    "df_chunk = pd.DataFrame()\n",
    "\n",
    "df_tweets = pd.concat(list_tweets, axis= 0)\n",
    "df_tweets = df_tweets.drop_duplicates('id')\n",
    "\n",
    "list_tweets = []\n",
    "df_tweets.to_csv('df_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>extended</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>full_text</th>\n",
       "      <th>user_name</th>\n",
       "      <th>verified</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_listed_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_created_at</th>\n",
       "      <th>retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>932568009427816449</td>\n",
       "      <td>Mon Nov 20 11:15:14 +0000 2017</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>['Pimkie_ES']</td>\n",
       "      <td>['descuento', 'BlackFriday', 'ccrosaleda']</td>\n",
       "      <td>['Los dÃ­as 23, 24 y 25 de Noviembre disfruta d...</td>\n",
       "      <td>ccrosaleda</td>\n",
       "      <td>False</td>\n",
       "      <td>11108</td>\n",
       "      <td>10546</td>\n",
       "      <td>1346</td>\n",
       "      <td>77</td>\n",
       "      <td>9373</td>\n",
       "      <td>Wed Nov 16 09:34:33 +0000 2011</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>932568012443602945</td>\n",
       "      <td>Mon Nov 20 11:15:15 +0000 2017</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>['BlackFriday2017']</td>\n",
       "      <td>['CHOLLO #BlackFriday2017 ðŸ–¤ FIFA 18 EdiciÃ³n Es...</td>\n",
       "      <td>soydechollos</td>\n",
       "      <td>False</td>\n",
       "      <td>6001</td>\n",
       "      <td>48</td>\n",
       "      <td>539</td>\n",
       "      <td>145</td>\n",
       "      <td>12642</td>\n",
       "      <td>Thu Apr 23 18:58:21 +0000 2015</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>932568026246975488</td>\n",
       "      <td>Mon Nov 20 11:15:18 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>['AMAZON', 'DEALS', 'Christmas', 'holiday', 't...</td>\n",
       "      <td>['HURRY #AMAZON LIGHTNING #DEALS LIVE &amp;gt; htt...</td>\n",
       "      <td>CouponsFreebie</td>\n",
       "      <td>False</td>\n",
       "      <td>54691</td>\n",
       "      <td>11508</td>\n",
       "      <td>101</td>\n",
       "      <td>667</td>\n",
       "      <td>42325</td>\n",
       "      <td>Fri Oct 24 03:28:08 +0000 2008</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>932568026494283776</td>\n",
       "      <td>Mon Nov 20 11:15:18 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>['blackfriday']</td>\n",
       "      <td>['BlackFriday', 'CORSETS', 'dress', 'fashion']</td>\n",
       "      <td>['Black Friday Sale- 55% Off\\nNayla Brocade Ov...</td>\n",
       "      <td>corsetsqueen</td>\n",
       "      <td>False</td>\n",
       "      <td>216</td>\n",
       "      <td>1592</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1133</td>\n",
       "      <td>Tue Sep 27 00:55:29 +0000 2011</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>932568027010404354</td>\n",
       "      <td>Mon Nov 20 11:15:18 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>['ghd', 'Christmas', 'hair', 'BlackFriday', 'B...</td>\n",
       "      <td>['Black Friday Deals\\nSave Â£20 on the ghd IV S...</td>\n",
       "      <td>TerencePaulShop</td>\n",
       "      <td>False</td>\n",
       "      <td>6929</td>\n",
       "      <td>594</td>\n",
       "      <td>256</td>\n",
       "      <td>30</td>\n",
       "      <td>4721</td>\n",
       "      <td>Mon Nov 19 07:39:50 +0000 2012</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                      created_at language  coordinates  \\\n",
       "0  932568009427816449  Mon Nov 20 11:15:14 +0000 2017       es          NaN   \n",
       "1  932568012443602945  Mon Nov 20 11:15:15 +0000 2017       es          NaN   \n",
       "2  932568026246975488  Mon Nov 20 11:15:18 +0000 2017       en          NaN   \n",
       "3  932568026494283776  Mon Nov 20 11:15:18 +0000 2017       en          NaN   \n",
       "4  932568027010404354  Mon Nov 20 11:15:18 +0000 2017       en          NaN   \n",
       "\n",
       "   extended    user_mentions  \\\n",
       "0      True    ['Pimkie_ES']   \n",
       "1      True               []   \n",
       "2     False               []   \n",
       "3      True  ['blackfriday']   \n",
       "4      True               []   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0         ['descuento', 'BlackFriday', 'ccrosaleda']   \n",
       "1                                ['BlackFriday2017']   \n",
       "2  ['AMAZON', 'DEALS', 'Christmas', 'holiday', 't...   \n",
       "3     ['BlackFriday', 'CORSETS', 'dress', 'fashion']   \n",
       "4  ['ghd', 'Christmas', 'hair', 'BlackFriday', 'B...   \n",
       "\n",
       "                                           full_text        user_name  \\\n",
       "0  ['Los dÃ­as 23, 24 y 25 de Noviembre disfruta d...       ccrosaleda   \n",
       "1  ['CHOLLO #BlackFriday2017 ðŸ–¤ FIFA 18 EdiciÃ³n Es...     soydechollos   \n",
       "2  ['HURRY #AMAZON LIGHTNING #DEALS LIVE &gt; htt...   CouponsFreebie   \n",
       "3  ['Black Friday Sale- 55% Off\\nNayla Brocade Ov...     corsetsqueen   \n",
       "4  ['Black Friday Deals\\nSave Â£20 on the ghd IV S...  TerencePaulShop   \n",
       "\n",
       "   verified  user_followers  user_friends  user_favourites_count  \\\n",
       "0     False           11108         10546                   1346   \n",
       "1     False            6001            48                    539   \n",
       "2     False           54691         11508                    101   \n",
       "3     False             216          1592                      0   \n",
       "4     False            6929           594                    256   \n",
       "\n",
       "   user_listed_count  user_statuses_count                 user_created_at  \\\n",
       "0                 77                 9373  Wed Nov 16 09:34:33 +0000 2011   \n",
       "1                145                12642  Thu Apr 23 18:58:21 +0000 2015   \n",
       "2                667                42325  Fri Oct 24 03:28:08 +0000 2008   \n",
       "3                  1                 1133  Tue Sep 27 00:55:29 +0000 2011   \n",
       "4                 30                 4721  Mon Nov 19 07:39:50 +0000 2012   \n",
       "\n",
       "   retweet  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  \n",
       "3    False  \n",
       "4    False  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up the memory if you need to\n",
    "df_tweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_retweets = glob('output/retweets*')\n",
    "\n",
    "list_retweets = []\n",
    "\n",
    "for filename in filenames_retweets:\n",
    "    df_chunk = pd.read_csv(filename)\n",
    "    list_retweets.append(df_chunk)\n",
    "\n",
    "# Free up the memory\n",
    "df_chunk = pd.DataFrame()\n",
    "\n",
    "df_retweets = pd.concat(list_retweets, axis= 0)\n",
    "df_retweets = df_retweets.drop_duplicates('id')\n",
    "\n",
    "list_retweets = []\n",
    "df_retweets.to_csv('df_retweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>language</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>extended</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>full_text</th>\n",
       "      <th>user_name</th>\n",
       "      <th>verified</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet</th>\n",
       "      <th>orig_id</th>\n",
       "      <th>orig_created_at</th>\n",
       "      <th>orig_user</th>\n",
       "      <th>orig_user_followers</th>\n",
       "      <th>orig_user_friends</th>\n",
       "      <th>orig_user_favourites</th>\n",
       "      <th>orig_user_listed</th>\n",
       "      <th>orig_user_statuses</th>\n",
       "      <th>orig_user_created_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>932568005795614720</td>\n",
       "      <td>Mon Nov 20 11:15:13 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>['BlackFriday2017', 'BlackFridayFeeling', 'Bla...</td>\n",
       "      <td>['Racism will never end while cheap and discou...</td>\n",
       "      <td>dalisufakude</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>932527666804256768</td>\n",
       "      <td>Mon Nov 20 08:34:55 +0000 2017</td>\n",
       "      <td>Amina_Diallo1</td>\n",
       "      <td>44</td>\n",
       "      <td>444</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>170</td>\n",
       "      <td>Mon Aug 15 13:31:28 +0000 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>932568007938887680</td>\n",
       "      <td>Mon Nov 20 11:15:14 +0000 2017</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>['DecathlonES']</td>\n",
       "      <td>['BlackFriday']</td>\n",
       "      <td>['Algunos listillos quieren aprovechar el #Bla...</td>\n",
       "      <td>retenex</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>932540839582162945</td>\n",
       "      <td>Mon Nov 20 09:27:16 +0000 2017</td>\n",
       "      <td>policia</td>\n",
       "      <td>3049485</td>\n",
       "      <td>0</td>\n",
       "      <td>25781</td>\n",
       "      <td>7875</td>\n",
       "      <td>22662</td>\n",
       "      <td>Wed Mar 11 17:02:34 +0000 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>932568008790298630</td>\n",
       "      <td>Mon Nov 20 11:15:14 +0000 2017</td>\n",
       "      <td>fr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>['cheissoux', 'franceinter']</td>\n",
       "      <td>['BlackFriday', 'obsolescence', 'GreenFriday']</td>\n",
       "      <td>['Stop au #BlackFriday &amp;amp; Ã  l\\'#obsolescenc...</td>\n",
       "      <td>MathieuRama24</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>932564925699981312</td>\n",
       "      <td>Mon Nov 20 11:02:59 +0000 2017</td>\n",
       "      <td>Envie_org</td>\n",
       "      <td>1646</td>\n",
       "      <td>626</td>\n",
       "      <td>421</td>\n",
       "      <td>100</td>\n",
       "      <td>1574</td>\n",
       "      <td>Thu Jul 31 11:07:33 +0000 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>932568013274058752</td>\n",
       "      <td>Mon Nov 20 11:15:15 +0000 2017</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>['BlackFriday', 'BlackFriday']</td>\n",
       "      <td>['Ah! pero espera, que esto MOLA MIL!! Sabes q...</td>\n",
       "      <td>bimbayorkshire</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>932565511086444544</td>\n",
       "      <td>Mon Nov 20 11:05:18 +0000 2017</td>\n",
       "      <td>JaponShop</td>\n",
       "      <td>19033</td>\n",
       "      <td>1932</td>\n",
       "      <td>8722</td>\n",
       "      <td>183</td>\n",
       "      <td>23708</td>\n",
       "      <td>Fri Oct 30 00:14:09 +0000 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>932568013651480577</td>\n",
       "      <td>Mon Nov 20 11:15:15 +0000 2017</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>['BlackFriday2017', 'BlackDiamond', 'HGJG', 'L...</td>\n",
       "      <td>['On #BlackFriday2017 you could win #BlackDiam...</td>\n",
       "      <td>Hannytravels</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>932564465010331648</td>\n",
       "      <td>Mon Nov 20 11:01:09 +0000 2017</td>\n",
       "      <td>HGJG_VIP</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>Wed Apr 05 08:43:29 +0000 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                      created_at language  coordinates  \\\n",
       "0  932568005795614720  Mon Nov 20 11:15:13 +0000 2017       en          NaN   \n",
       "1  932568007938887680  Mon Nov 20 11:15:14 +0000 2017       es          NaN   \n",
       "2  932568008790298630  Mon Nov 20 11:15:14 +0000 2017       fr          NaN   \n",
       "3  932568013274058752  Mon Nov 20 11:15:15 +0000 2017       es          NaN   \n",
       "4  932568013651480577  Mon Nov 20 11:15:15 +0000 2017       en          NaN   \n",
       "\n",
       "   extended                 user_mentions  \\\n",
       "0      True                            []   \n",
       "1      True               ['DecathlonES']   \n",
       "2      True  ['cheissoux', 'franceinter']   \n",
       "3      True                            []   \n",
       "4      True                            []   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0  ['BlackFriday2017', 'BlackFridayFeeling', 'Bla...   \n",
       "1                                    ['BlackFriday']   \n",
       "2     ['BlackFriday', 'obsolescence', 'GreenFriday']   \n",
       "3                     ['BlackFriday', 'BlackFriday']   \n",
       "4  ['BlackFriday2017', 'BlackDiamond', 'HGJG', 'L...   \n",
       "\n",
       "                                           full_text       user_name  \\\n",
       "0  ['Racism will never end while cheap and discou...    dalisufakude   \n",
       "1  ['Algunos listillos quieren aprovechar el #Bla...         retenex   \n",
       "2  ['Stop au #BlackFriday &amp; Ã  l\\'#obsolescenc...   MathieuRama24   \n",
       "3  ['Ah! pero espera, que esto MOLA MIL!! Sabes q...  bimbayorkshire   \n",
       "4  ['On #BlackFriday2017 you could win #BlackDiam...    Hannytravels   \n",
       "\n",
       "   verified               ...                retweet             orig_id  \\\n",
       "0     False               ...                   True  932527666804256768   \n",
       "1      True               ...                   True  932540839582162945   \n",
       "2     False               ...                   True  932564925699981312   \n",
       "3     False               ...                   True  932565511086444544   \n",
       "4     False               ...                   True  932564465010331648   \n",
       "\n",
       "                  orig_created_at      orig_user  orig_user_followers  \\\n",
       "0  Mon Nov 20 08:34:55 +0000 2017  Amina_Diallo1                   44   \n",
       "1  Mon Nov 20 09:27:16 +0000 2017        policia              3049485   \n",
       "2  Mon Nov 20 11:02:59 +0000 2017      Envie_org                 1646   \n",
       "3  Mon Nov 20 11:05:18 +0000 2017      JaponShop                19033   \n",
       "4  Mon Nov 20 11:01:09 +0000 2017       HGJG_VIP                  238   \n",
       "\n",
       "  orig_user_friends  orig_user_favourites  orig_user_listed  \\\n",
       "0               444                    45                 0   \n",
       "1                 0                 25781              7875   \n",
       "2               626                   421               100   \n",
       "3              1932                  8722               183   \n",
       "4               135                    12                 0   \n",
       "\n",
       "  orig_user_statuses            orig_user_created_at  \n",
       "0                170  Mon Aug 15 13:31:28 +0000 2011  \n",
       "1              22662  Wed Mar 11 17:02:34 +0000 2009  \n",
       "2               1574  Thu Jul 31 11:07:33 +0000 2014  \n",
       "3              23708  Fri Oct 30 00:14:09 +0000 2009  \n",
       "4                127  Wed Apr 05 08:43:29 +0000 2017  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_retweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free up the memory if you need to\n",
    "df_retweets = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
